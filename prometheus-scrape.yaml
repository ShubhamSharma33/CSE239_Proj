apiVersion: v1
kind: Service
metadata:
  name: llm-inference-metrics
  namespace: llm-inference
  labels:
    app: llm-inference
spec:
  selector:
    app: llm-inference
  ports:
  - name: metrics
    port: 8080
    targetPort: 8080
---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: llm-inference
  namespace: llm-inference
spec:
  selector:
    matchLabels:
      app: llm-inference
  endpoints:
  - port: metrics
    path: /metrics
    interval: 15s
